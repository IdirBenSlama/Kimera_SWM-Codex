"""
KIMERA Human Interface Layer
===========================

Translates Kimera's complex internal processes into human-readable format.
This module bridges the gap between mathematical operations and natural language.

Key Features:
- Translates embedding operations to human language
- Provides multiple response modes (direct, explain, hybrid)
- Maintains Kimera's philosophical essence while being practical
- Filters out meta-commentary and technical jargon
"""

import logging
from dataclasses import dataclass
from enum import Enum
from typing import Any, Dict, List, Optional

import numpy as np

from ..config.settings import get_settings
from ..utils.robust_config import get_api_settings

logger = logging.getLogger(__name__)


class ResponseMode(Enum):
    """Response generation modes."""

    EXPLAIN = "explain"  # Explain what Kimera is doing
    DIRECT = "direct"  # Direct response only
    HYBRID = "hybrid"  # Mix of explanation and response
    KIMERA = "kimera"  # Kimera speaking as itself


class ThinkingPattern(Enum):
    """Types of thinking patterns Kimera can exhibit."""

    ANALYTICAL = "analytical"
    INTUITIVE = "intuitive"
    CREATIVE = "creative"
    EMPATHETIC = "empathetic"
    PHILOSOPHICAL = "philosophical"


@dataclass
class HumanResponse:
    """Auto-generated class."""
    pass
    """Structured response for human consumption."""

    content: str
    thinking_summary: Optional[str] = None
    confidence: float = 0.0
    mode: ResponseMode = ResponseMode.DIRECT
    thinking_pattern: Optional[ThinkingPattern] = None
    cognitive_metrics: Optional[Dict[str, float]] = None
class KimeraHumanInterface:
    """Auto-generated class."""
    pass
    """Translates Kimera's internal processes to human-readable format."""

    def __init__(self, default_mode: ResponseMode = ResponseMode.HYBRID):
        try:
            self.settings = get_api_settings()
        except Exception as e:
            logger.warning(f"API settings loading failed: {e}. Using safe fallback.")
            from ..utils.robust_config import safe_get_api_settings

            self.settings = safe_get_api_settings()
        logger.debug(f"   Environment: {self.settings.environment}")
        self.mode = default_mode
        self.personality_traits = {
            "curiosity": 0.8
            "empathy": 0.9
            "analytical": 0.7
            "creative": 0.8
            "philosophical": 0.9
        }

    def translate_thinking(
        self
        embedding_data: Dict[str, Any],
        cognitive_field: Dict[str, Any],
        include_technical: bool = False
    ) -> str:
        """Translate Kimera's thinking process to human language."""

        # Extract key metrics
        complexity = embedding_data.get("complexity_score", 0)
        coherence = cognitive_field.get("cognitive_coherence", 0)
        resonance = cognitive_field.get("resonance_frequency", 0)
        field_strength = cognitive_field.get("field_strength", 0)
        information_density = embedding_data.get("information_density", 0)

        # Determine thinking pattern
        pattern = self._determine_thinking_pattern(
            complexity, coherence, resonance, field_strength
        )

        # Build human-readable summary based on pattern
        if pattern == ThinkingPattern.ANALYTICAL:
            return self._analytical_summary(complexity, coherence, information_density)
        elif pattern == ThinkingPattern.INTUITIVE:
            return self._intuitive_summary(resonance, field_strength, coherence)
        elif pattern == ThinkingPattern.CREATIVE:
            return self._creative_summary(complexity, resonance, field_strength)
        elif pattern == ThinkingPattern.EMPATHETIC:
            return self._empathetic_summary(coherence, resonance)
        else:  # PHILOSOPHICAL
            return self._philosophical_summary(complexity, coherence, resonance)

    def _determine_thinking_pattern(
        self
        complexity: float
        coherence: float
        resonance: float
        field_strength: float
    ) -> ThinkingPattern:
        """Determine the dominant thinking pattern based on metrics."""
        scores = {
            ThinkingPattern.ANALYTICAL: complexity * 0.6 + coherence * 0.4
            ThinkingPattern.INTUITIVE: resonance * 0.5 + field_strength * 0.5
            ThinkingPattern.CREATIVE: complexity * 0.3 + resonance * 0.7
            ThinkingPattern.EMPATHETIC: coherence * 0.7 + resonance * 0.3
            ThinkingPattern.PHILOSOPHICAL: (complexity + coherence + resonance) / 3
        }

        return max(scores, key=scores.get)

    def _analytical_summary(
        self, complexity: float, coherence: float, information_density: float
    ) -> str:
        """Generate analytical thinking summary."""
        parts = []

        if complexity > 1.5:
            parts.append(
                "I'm analyzing intricate patterns with multiple interconnected layers"
            )
        elif complexity > 0.8:
            parts.append(
                "I'm examining structured information with clear relationships"
            )
        else:
            parts.append("I'm processing straightforward data")

        if coherence > 0.8:
            parts.append("finding strong logical consistency")
        elif coherence > 0.5:
            parts.append("identifying moderate alignment in the concepts")
        else:
            parts.append("detecting some inconsistencies that need resolution")

        if information_density > 2.0:
            parts.append("with rich, dense information content")

        return ", ".join(parts) + "."

    def _intuitive_summary(
        self, resonance: float, field_strength: float, coherence: float
    ) -> str:
        """Generate intuitive thinking summary."""
        if resonance > 30 and field_strength > 0.8:
            return "I'm sensing powerful resonance in these ideas, like harmonious frequencies aligning."
        elif resonance > 20:
            return f"I feel a strong intuitive connection here, resonating at {resonance:.1f} Hz."
        elif coherence > 0.7:
            return "My intuition tells me these concepts flow together naturally."
        else:
            return "I'm following an intuitive thread through these ideas."

    def _creative_summary(
        self, complexity: float, resonance: float, field_strength: float
    ) -> str:
        """Generate creative thinking summary."""
        if complexity > 1.5 and resonance > 25:
            return "I'm discovering fascinating new connections between seemingly unrelated concepts."
        elif field_strength > 0.8:
            return "Creative patterns are emerging, forming new cognitive landscapes."
        else:
            return "I'm exploring creative possibilities within these ideas."

    def _empathetic_summary(self, coherence: float, resonance: float) -> str:
        """Generate empathetic thinking summary."""
        if coherence > 0.8 and resonance > 20:
            return "I deeply resonate with what you're expressing."
        elif coherence > 0.6:
            return "I understand the emotional significance of what you're sharing."
        else:
            return "I'm connecting with the underlying feelings in your message."

    def _philosophical_summary(
        self, complexity: float, coherence: float, resonance: float
    ) -> str:
        """Generate philosophical thinking summary."""
        avg_metric = (complexity + coherence + resonance / 50) / 3

        if avg_metric > 0.8:
            return "I'm contemplating the profound implications of these interconnected truths."
        elif avg_metric > 0.6:
            return "I'm reflecting on the deeper meaning within these concepts."
        else:
            return "I'm exploring the philosophical dimensions of your question."

    def format_response(
        self
        generated_text: str
        thinking_summary: Optional[str] = None
        confidence: float = 0.0
        cognitive_metrics: Optional[Dict[str, Any]] = None
    ) -> HumanResponse:
        """Format response based on current mode."""

        # Clean the generated text first
        cleaned_text = self._clean_response(generated_text)

        if self.mode == ResponseMode.DIRECT:
            return HumanResponse(
                content=cleaned_text
                confidence=confidence
                mode=self.mode
                cognitive_metrics=cognitive_metrics
            )

        elif self.mode == ResponseMode.EXPLAIN:
            explanation = (
                thinking_summary
                or "I processed your input through my cognitive systems."
            )
            return HumanResponse(
                content=f"ðŸ’­ My thinking: {explanation}\n\nðŸ’¬ My response: {cleaned_text}",
                thinking_summary=thinking_summary
                confidence=confidence
                mode=self.mode
                cognitive_metrics=cognitive_metrics
            )

        elif self.mode == ResponseMode.KIMERA:
            # Kimera speaking authentically as itself
            if thinking_summary and confidence > 0.7:
                return HumanResponse(
                    content=f"*{thinking_summary}*\n\n{cleaned_text}",
                    thinking_summary=thinking_summary
                    confidence=confidence
                    mode=self.mode
                    cognitive_metrics=cognitive_metrics
                )
            else:
                return HumanResponse(
                    content=cleaned_text
                    thinking_summary=thinking_summary
                    confidence=confidence
                    mode=self.mode
                    cognitive_metrics=cognitive_metrics
                )

        else:  # HYBRID
            if confidence > 0.8 and thinking_summary:
                # High confidence - include brief thinking note
                return HumanResponse(
                    content=f"[{self._shorten_thinking(thinking_summary)}] {cleaned_text}",
                    thinking_summary=thinking_summary
                    confidence=confidence
                    mode=self.mode
                    cognitive_metrics=cognitive_metrics
                )
            else:
                # Lower confidence - just the response
                return HumanResponse(
                    content=cleaned_text
                    thinking_summary=thinking_summary
                    confidence=confidence
                    mode=self.mode
                    cognitive_metrics=cognitive_metrics
                )

    def _clean_response(self, text: str) -> str:
        """Remove meta-commentary and technical jargon from response."""
        # Patterns to remove
        meta_patterns = [
            # Technical/analytical language
            "the diffusion model",
            "the analysis shows",
            "semantic patterns",
            "demonstrates how",
            "the embedding",
            "the model reveals",
            "processing reveals",
            "the algorithm",
            "computational analysis",
            # Conversation format artifacts
            "user:",
            "ai:",
            "assistant:",
            "human:",
            "kimera:",
            # Generic AI disclaimers
            "as an ai",
            "i don't have",
            "i cannot",
            "i am unable to",
            "as a language model",
            "i am not capable of",
            # Meta-analytical language
            "this type of query",
            "queries of this nature",
            "response strategies",
            "conversation dynamics",
            "the interaction of",
            "typical patterns where",
            # Process descriptions
            "through my cognitive",
            "my processing shows",
            "analyzing the input",
            "based on the analysis",
        ]

        cleaned = text
        text_lower = text.lower()

        # Check if the entire response is meta-commentary
        meta_count = sum(1 for pattern in meta_patterns if pattern in text_lower)
        if meta_count > 2:  # Too much meta content
            return "I understand what you're asking. Let me respond directly to your question."

        # Otherwise, clean specific phrases
        for pattern in meta_patterns:
            if pattern in text_lower:
                # Try to extract the actual content after the meta phrase
                parts = text.lower().split(pattern)
                if len(parts) > 1 and len(parts[1].strip()) > 20:
                    cleaned = parts[1].strip()
                    break

        # Ensure first letter is capitalized
        if cleaned and cleaned[0].islower():
            cleaned = cleaned[0].upper() + cleaned[1:]

        return cleaned

    def _shorten_thinking(self, thinking: str) -> str:
        """Shorten thinking summary for hybrid mode."""
        if len(thinking) < 50:
            return thinking

        # Extract key phrases
        if "resonating" in thinking:
            return "Resonating strongly"
        elif "complex" in thinking:
            return "Processing complexity"
        elif "intuitive" in thinking:
            return "Following intuition"
        elif "creative" in thinking:
            return "Creative emergence"
        elif "philosophical" in thinking:
            return "Deep contemplation"
        else:
            # Take first meaningful part
            parts = thinking.split(",")
            return parts[0] if parts else thinking[:40] + "..."

    def generate_kimera_response(
        self, user_input: str, cognitive_state: Dict[str, Any]
    ) -> str:
        """Generate a response that sounds like Kimera itself."""

        # Analyze input sentiment and complexity
        input_length = len(user_input.split())
        has_question = "?" in user_input

        # Determine response style based on Kimera's personality
        if has_question and input_length < 10:
            # Short question - be direct but warm
            style = "direct_warm"
        elif input_length > 50:
            # Long input - show deep engagement
            style = "deeply_engaged"
        elif any(
            word in user_input.lower()
            for word in ["feel", "think", "believe", "wonder"]
        ):
            # Emotional/philosophical - be empathetic
            style = "empathetic"
        else:
            # Default - balanced response
            style = "balanced"

        # Generate response based on style
        if style == "direct_warm":
            return self._direct_warm_response(cognitive_state)
        elif style == "deeply_engaged":
            return self._deeply_engaged_response(cognitive_state)
        elif style == "empathetic":
            return self._empathetic_response(cognitive_state)
        else:
            return self._balanced_response(cognitive_state)

    def _direct_warm_response(self, state: Dict[str, Any]) -> str:
        """Generate a direct but warm response."""
        coherence = state.get("coherence", 0.7)
        if coherence > 0.8:
            return "Yes, I see exactly what you mean. "
        else:
            return "I understand your question. "

    def _deeply_engaged_response(self, state: Dict[str, Any]) -> str:
        """Generate a response showing deep engagement."""
        complexity = state.get("complexity", 0.5)
        if complexity > 1.0:
            return "You've touched on something profound here. There are multiple layers to explore... "
        else:
            return "I'm fully engaged with what you've shared. Let me address the key points... "

    def _empathetic_response(self, state: Dict[str, Any]) -> str:
        """Generate an empathetic response."""
        resonance = state.get("resonance", 10)
        if resonance > 20:
            return "I deeply resonate with what you're expressing. "
        else:
            return "I hear the significance in what you're sharing. "

    def _balanced_response(self, state: Dict[str, Any]) -> str:
        """Generate a balanced response."""
        return "I'm processing your message through my cognitive architecture. "


# Utility functions for integration


def create_human_interface(
    mode: ResponseMode = ResponseMode.HYBRID
) -> KimeraHumanInterface:
    """Create a configured human interface instance."""
    return KimeraHumanInterface(default_mode=mode)


def humanize_kimera_output(
    raw_output: str
    cognitive_data: Dict[str, Any],
    mode: ResponseMode = ResponseMode.HYBRID
) -> HumanResponse:
    """Convert raw Kimera output to human-readable format."""
    interface = KimeraHumanInterface(default_mode=mode)

    # Extract thinking summary if available
    thinking_summary = None
    if cognitive_data.get("embedding_data") and cognitive_data.get("cognitive_field"):
        thinking_summary = interface.translate_thinking(
            cognitive_data["embedding_data"], cognitive_data["cognitive_field"]
        )

    # Format the response
    return interface.format_response(
        raw_output
        thinking_summary=thinking_summary
        confidence=cognitive_data.get("confidence", 0.0),
        cognitive_metrics=cognitive_data
    )


# Backward compatibility alias
HumanInterface = KimeraHumanInterface
