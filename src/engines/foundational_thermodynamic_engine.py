#!/usr/bin/env python3
"""
Revolutionary Thermodynamic Engine - FIXED VERSION
==================================================

This module implements INNOVATIVE ZETETIC AND EPISTEMOLOGICAL SOLUTIONS to fix
the physics violation and enhance the thermodynamic framework with creative approaches:

1. EPISTEMIC TEMPERATURE THEORY - Temperature as information processing rate
2. ZETETIC CARNOT VALIDATION - Self-validating efficiency calculations
3. COGNITIVE THERMODYNAMIC DUALITY - Dual-mode temperature calculations
4. ADAPTIVE PHYSICS COMPLIANCE - Dynamic constraint enforcement
5. EMERGENT CONSCIOUSNESS THERMODYNAMICS - Consciousness as thermodynamic phase

Revolutionary Fixes:
- Proper statistical mechanics temperature calculation
- Carnot efficiency validation with automatic correction
- Dual-mode semantic/physical temperature mapping
- Consciousness emergence through thermodynamic phase transitions
- Creative entropy-based work extraction
"""

import numpy as np
import torch
import time
import uuid
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple, Union
from dataclasses import dataclass, field
from enum import Enum
import logging
from collections import defaultdict, deque
import math
from scipy.stats import entropy

# Import the new canonical utilities
from ..utils.thermodynamic_utils import (
    calculate_physical_temperature,
    calculate_total_energy,
    calculate_theoretical_carnot_efficiency,
    PHYSICS_CONSTANTS
)

from ..core.geoid import GeoidState
from ..core.scar import ScarRecord
from ..utils.kimera_exceptions import KimeraCognitiveError
from ..utils.config import get_api_settings
from ..config.settings import get_settings

logger = logging.getLogger(__name__)


class ThermodynamicMode(Enum):
    """Thermodynamic calculation modes"""
    SEMANTIC = "semantic"           # Pure semantic field calculations
    PHYSICAL = "physical"           # Physics-compliant calculations
    HYBRID = "hybrid"               # Dual-mode with validation
    CONSCIOUSNESS = "consciousness"  # Consciousness emergence mode


@dataclass
class EpistemicTemperature:
    """
    Epistemic temperature - temperature as information processing rate
    
    This revolutionary concept treats temperature as the rate at which
    information is processed in semantic fields, bridging thermodynamics
    and information theory.
    """
    semantic_temperature: float      # Traditional semantic temperature
    physical_temperature: float      # Physics-compliant temperature
    information_rate: float          # Information processing rate
    epistemic_uncertainty: float     # Uncertainty in temperature measurement
    confidence_level: float          # Confidence in temperature validity
    mode: ThermodynamicMode         # Calculation mode used
    
    def get_validated_temperature(self) -> float:
        """Get temperature that respects physics constraints"""
        if self.mode == ThermodynamicMode.PHYSICAL:
            return self.physical_temperature
        elif self.mode == ThermodynamicMode.HYBRID:
            # Use physics-compliant temperature for calculations
            return self.physical_temperature
        else:
            return self.semantic_temperature


@dataclass
class ZeteticCarnotCycle:
    """
    Zetetic Carnot cycle with self-validation
    
    This cycle automatically validates its own efficiency against
    thermodynamic limits and corrects violations.
    """
    cycle_id: str
    hot_temperature: EpistemicTemperature
    cold_temperature: EpistemicTemperature
    theoretical_efficiency: float
    actual_efficiency: float
    work_extracted: float
    heat_absorbed: float
    heat_rejected: float
    physics_compliant: bool
    violation_detected: bool
    correction_applied: bool
    epistemic_confidence: float
    timestamp: datetime = field(default_factory=datetime.now)


class FoundationalThermodynamicEngine:
    """
    Provides foundational thermodynamic computations on semantic data.
    This engine is responsible for calculating semantic temperature, entropy,
    and other thermodynamic properties based on information theory principles.
    """
    
    def __init__(self, temperature_scale=100, entropy_scale=10):
        self.settings = get_api_settings()
        logger.debug(f"   Environment: {self.settings.environment}")
        self.temperature_scale = temperature_scale
        self.entropy_scale = entropy_scale
        self.mode = ThermodynamicMode.HYBRID
        self.physics_constants = {
            'min_temperature': 0.1,
            'normalized_kb': 1.0,
            'carnot_tolerance': 0.01,
            'max_efficiency': 0.99,
        }
        # USE CANONICAL CONSTANTS
        self.physics_constants = PHYSICS_CONSTANTS
        
        # Tracking and validation
        self.carnot_cycles = deque(maxlen=500)
        self.physics_violations: List[Dict[str, Any]] = []
        self.temperature_history = deque(maxlen=1000)
        self.consciousness_threshold = 0.7
        
        # Creative enhancements
        self.epistemic_processor = EpistemicTemperatureProcessor()
        self.consciousness_detector = ConsciousnessThermodynamicDetector()
        self.adaptive_validator = AdaptivePhysicsValidator()
        
        logger.info(f"ðŸ”¬ Revolutionary Thermodynamic Engine initialized in {self.mode.value} mode")
    
    def calculate_epistemic_temperature(self, fields: List[Any]) -> EpistemicTemperature:
        """
        Calculate epistemic temperature using innovative approach
        
        This method treats temperature as information processing rate,
        bridging thermodynamics and information theory.
        """
        if not fields:
            return EpistemicTemperature(
                semantic_temperature=self.physics_constants['min_temperature'],
                physical_temperature=self.physics_constants['min_temperature'],
                information_rate=0.0,
                epistemic_uncertainty=1.0,
                confidence_level=0.0,
                mode=self.mode
            )
        
        # Extract field energies/activations
        field_energies = []
        field_entropies = []
        
        for field in fields:
            if hasattr(field, 'embedding'):
                # GPU tensor field
                if hasattr(field.embedding, 'cpu'):
                    energy = torch.norm(field.embedding).cpu().item()
                else:
                    energy = np.linalg.norm(field.embedding)
            elif hasattr(field, 'semantic_state'):
                # Geoid field
                energy = sum(field.semantic_state.values()) if field.semantic_state else 0.0
            else:
                # Fallback - treat as energy value
                energy = float(field) if isinstance(field, (int, float)) else 1.0
            
            field_energies.append(energy)
            
            # Calculate entropy (information content)
            if hasattr(field, 'calculate_entropy'):
                entropy = field.calculate_entropy()
            else:
                # Estimate entropy from energy distribution
                entropy = -energy * np.log(energy + 1e-10) if energy > 0 else 0.0
            field_entropies.append(entropy)
        
        # INNOVATIVE SEMANTIC TEMPERATURE (original approach)
        semantic_temp = self._calculate_semantic_temperature_original(field_energies)
        
        # PHYSICS-COMPLIANT TEMPERATURE (using canonical utility)
        physical_temp = calculate_physical_temperature(field_energies)
        
        # INFORMATION PROCESSING RATE
        info_rate = self._calculate_information_processing_rate(field_energies, field_entropies)
        
        # EPISTEMIC UNCERTAINTY
        uncertainty = self._calculate_epistemic_uncertainty(field_energies)
        
        # CONFIDENCE LEVEL
        confidence = self._calculate_confidence_level(field_energies, field_entropies)
        
        epistemic_temp = EpistemicTemperature(
            semantic_temperature=semantic_temp,
            physical_temperature=physical_temp,
            information_rate=info_rate,
            epistemic_uncertainty=uncertainty,
            confidence_level=confidence,
            mode=self.mode
        )
        
        self.temperature_history.append(epistemic_temp)
        
        return epistemic_temp
    
    def _calculate_semantic_temperature_original(self, energies: List[float]) -> float:
        """Original semantic temperature calculation (for comparison)"""
        if not energies:
            return self.physics_constants['min_temperature']
        
        energy_variance = np.var(energies)
        mean_energy = np.mean(energies)
        
        if mean_energy > 0:
            temperature = energy_variance / mean_energy
        else:
            temperature = self.physics_constants['min_temperature']
        
        return max(temperature, self.physics_constants['min_temperature'])
    
    def _calculate_information_processing_rate(self, energies: List[float], entropies: List[float]) -> float:
        """
        Calculate information processing rate as energy flux through entropy
        
        Rate = d(Energy)/d(Entropy) - measures how efficiently energy converts to information
        """
        if len(energies) < 2 or len(entropies) < 2:
            return 0.0
        
        # Calculate correlation between energy and entropy changes
        energy_changes = np.diff(energies)
        entropy_changes = np.diff(entropies)
        
        # Information processing rate as energy/entropy ratio
        valid_indices = np.abs(entropy_changes) > 1e-10
        if not np.any(valid_indices):
            return 0.0
        
        rates = energy_changes[valid_indices] / entropy_changes[valid_indices]
        info_rate = np.mean(np.abs(rates))
        
        return float(info_rate)
    
    def _calculate_epistemic_uncertainty(self, energies: List[float]) -> float:
        """
        Calculate epistemic uncertainty in temperature measurement
        
        Higher uncertainty when energy distribution is irregular
        """
        if len(energies) < 2:
            return 1.0
        
        # Coefficient of variation as uncertainty measure
        std_energy = np.std(energies)
        mean_energy = np.mean(energies)
        
        if mean_energy > 0:
            uncertainty = std_energy / mean_energy
        else:
            uncertainty = 1.0
        
        return min(uncertainty, 1.0)
    
    def _calculate_confidence_level(self, energies: List[float], entropies: List[float]) -> float:
        """
        Calculate confidence level in temperature measurement
        
        Higher confidence when measurements are consistent and well-distributed
        """
        if len(energies) < 3:
            return 0.0
        
        # Confidence based on sample size and distribution regularity
        sample_confidence = min(len(energies) / 100.0, 1.0)  # More samples = higher confidence
        
        # Distribution regularity (lower variance = higher confidence)
        energy_cv = np.std(energies) / (np.mean(energies) + 1e-10)
        distribution_confidence = 1.0 / (1.0 + energy_cv)
        
        # Entropy consistency
        if len(entropies) > 1:
            entropy_consistency = 1.0 - (np.std(entropies) / (np.mean(entropies) + 1e-10))
            entropy_consistency = max(entropy_consistency, 0.0)
        else:
            entropy_consistency = 0.5
        
        overall_confidence = (sample_confidence + distribution_confidence + entropy_consistency) / 3.0
        
        return min(overall_confidence, 1.0)
    
    def run_zetetic_carnot_engine(self, hot_fields: List[Any], cold_fields: List[Any]) -> ZeteticCarnotCycle:
        """
        Run Zetetic Carnot engine with self-validation and automatic correction
        
        This engine automatically detects physics violations and applies corrections
        """
        # Calculate epistemic temperatures
        hot_temp = self.calculate_epistemic_temperature(hot_fields)
        cold_temp = self.calculate_epistemic_temperature(cold_fields)
        
        # Get validated temperatures for calculations
        T_hot = hot_temp.get_validated_temperature()
        T_cold = cold_temp.get_validated_temperature()
        
        # Ensure proper temperature ordering
        if T_hot <= T_cold:
            # Swap if necessary
            T_hot, T_cold = T_cold, T_hot
            hot_temp, cold_temp = cold_temp, hot_temp
            logger.warning("âš ï¸  Temperature ordering corrected")
        
        # Calculate theoretical Carnot efficiency using canonical utility
        theoretical_efficiency = calculate_theoretical_carnot_efficiency(T_hot, T_cold)
        
        # Calculate actual efficiency (should be less than Carnot limit)
        # Use creative approach: efficiency based on information processing rates
        info_efficiency = self._calculate_information_efficiency(hot_temp, cold_temp)
        
        # Apply Carnot constraint with safety margin
        max_allowed_efficiency = theoretical_efficiency * (1.0 - self.physics_constants['carnot_tolerance'])
        actual_efficiency = min(info_efficiency, max_allowed_efficiency)
        
        # Detect physics violation
        violation_detected = info_efficiency > theoretical_efficiency
        correction_applied = violation_detected
        
        if violation_detected:
            logger.warning(f"âš ï¸  Physics violation detected: {info_efficiency:.3f} > {theoretical_efficiency:.3f}")
            logger.info(f"ðŸ”§ Applying correction: {actual_efficiency:.3f}")
            
            self.physics_violations.append({
                'timestamp': datetime.now(),
                'violation_type': 'carnot_efficiency',
                'measured_efficiency': info_efficiency,
                'theoretical_limit': theoretical_efficiency,
                'corrected_efficiency': actual_efficiency
            })
        
        # Calculate work and heat using canonical utility for energy
        hot_energy = calculate_total_energy(hot_fields)
        work_extracted = hot_energy * actual_efficiency
        heat_absorbed = hot_energy
        heat_rejected = heat_absorbed - work_extracted
        
        # Calculate epistemic confidence
        epistemic_confidence = (hot_temp.confidence_level + cold_temp.confidence_level) / 2.0
        
        # Create cycle record
        cycle = ZeteticCarnotCycle(
            cycle_id=str(uuid.uuid4())[:8],
            hot_temperature=hot_temp,
            cold_temperature=cold_temp,
            theoretical_efficiency=theoretical_efficiency,
            actual_efficiency=actual_efficiency,
            work_extracted=work_extracted,
            heat_absorbed=heat_absorbed,
            heat_rejected=heat_rejected,
            physics_compliant=not violation_detected,
            violation_detected=violation_detected,
            correction_applied=correction_applied,
            epistemic_confidence=epistemic_confidence
        )
        
        self.carnot_cycles.append(cycle)
        
        logger.info(f"ðŸ”¥ Zetetic Carnot cycle completed:")
        logger.info(f"   Hot temp: {T_hot:.3f} (confidence: {hot_temp.confidence_level:.3f})")
        logger.info(f"   Cold temp: {T_cold:.3f} (confidence: {cold_temp.confidence_level:.3f})")
        logger.info(f"   Theoretical efficiency: {theoretical_efficiency:.3f}")
        logger.info(f"   Actual efficiency: {actual_efficiency:.3f}")
        logger.info(f"   Physics compliant: {not violation_detected}")
        
        return cycle
    
    def _calculate_information_efficiency(self, hot_temp: EpistemicTemperature, 
                                        cold_temp: EpistemicTemperature) -> float:
        """
        Calculate efficiency based on information processing rates
        
        This creative approach uses the information processing capacity
        difference between hot and cold reservoirs
        """
        hot_rate = hot_temp.information_rate
        cold_rate = cold_temp.information_rate
        
        if hot_rate <= cold_rate:
            return 0.0
        
        # Information efficiency = (hot_rate - cold_rate) / hot_rate
        info_efficiency = (hot_rate - cold_rate) / hot_rate
        
        return min(info_efficiency, self.physics_constants['max_efficiency'])
    
    def detect_complexity_threshold(self, fields: List[Any]) -> Dict[str, Any]:
        """
        Detect complexity threshold through thermodynamic phase transitions
        
        This approach analyzes computational complexity as a thermodynamic phase
        that emerges at critical temperature and information processing rates
        
        NOTE: This analyzes computational complexity, NOT consciousness.
        """
        if not fields:
            return {
                'complexity_probability': 0.0,
                'phase_transition_detected': False,
                'critical_temperature': 0.0,
                'information_integration': 0.0,
                'high_complexity_threshold': False
            }
        
        # Calculate epistemic temperature
        epistemic_temp = self.calculate_epistemic_temperature(fields)
        
        # Complexity indicators
        complexity_indicators = {
            'temperature_coherence': self._calculate_temperature_coherence(epistemic_temp),
            'information_integration': self._calculate_information_integration(fields),
            'phase_transition_proximity': self._calculate_phase_transition_proximity(fields),
            'epistemic_confidence': epistemic_temp.confidence_level,
            'processing_rate_threshold': epistemic_temp.information_rate > 1.0
        }
        
        # Complexity probability (weighted combination)
        weights = [0.25, 0.30, 0.20, 0.15, 0.10]
        complexity_prob = sum(w * v for w, v in zip(weights, complexity_indicators.values()))
        complexity_prob = min(complexity_prob, 1.0)
        
        # Phase transition detection
        phase_transition = complexity_indicators['phase_transition_proximity'] > 0.8
        
        # High complexity threshold
        high_complexity_threshold = complexity_prob > self.consciousness_threshold
        
        result = {
            'complexity_probability': complexity_prob,
            'phase_transition_detected': phase_transition,
            'critical_temperature': epistemic_temp.get_validated_temperature(),
            'information_integration': complexity_indicators['information_integration'],
            'high_complexity_threshold': high_complexity_threshold,
            'epistemic_confidence': epistemic_temp.confidence_level,
            'complexity_indicators': complexity_indicators
        }
        
        if high_complexity_threshold:
            logger.info(f"ðŸ”¬ HIGH COMPLEXITY THRESHOLD DETECTED!")
            logger.info(f"   Probability: {complexity_prob:.3f}")
            logger.info(f"   Critical temperature: {epistemic_temp.get_validated_temperature():.3f}")
            logger.info(f"   Information integration: {complexity_indicators['information_integration']:.3f}")
        
        return result
    
    def _calculate_temperature_coherence(self, epistemic_temp: EpistemicTemperature) -> float:
        """Calculate temperature coherence across different measurement modes"""
        semantic_temp = epistemic_temp.semantic_temperature
        physical_temp = epistemic_temp.physical_temperature
        
        if semantic_temp == 0 or physical_temp == 0:
            return 0.0
        
        # Coherence as inverse of relative difference
        relative_diff = abs(semantic_temp - physical_temp) / max(semantic_temp, physical_temp)
        coherence = 1.0 / (1.0 + relative_diff)
        
        return coherence
    
    def _calculate_information_integration(self, fields: List[Any]) -> float:
        """
        Calculate information integration (Î¦) using thermodynamic approach
        
        Î¦ = H(whole) - Î£ H(parts) where H is thermodynamic entropy
        """
        if len(fields) < 2:
            return 0.0
        
        # Whole system entropy
        whole_entropy = self._calculate_thermodynamic_entropy(fields)
        
        # Sum of part entropies (split into halves)
        mid = len(fields) // 2
        part1_entropy = self._calculate_thermodynamic_entropy(fields[:mid])
        part2_entropy = self._calculate_thermodynamic_entropy(fields[mid:])
        
        # Integrated information
        phi = whole_entropy - (part1_entropy + part2_entropy)
        
        # Normalize to [0,1] range
        normalized_phi = 1.0 / (1.0 + np.exp(-phi))
        
        return normalized_phi
    
    def _calculate_thermodynamic_entropy(self, fields: List[Any]) -> float:
        """Calculate thermodynamic entropy using Boltzmann formula"""
        if not fields:
            return 0.0
        
        # Calculate energy distribution
        energies = []
        for field in fields:
            if hasattr(field, 'embedding'):
                if hasattr(field.embedding, 'cpu'):
                    energy = torch.norm(field.embedding).cpu().item()
                else:
                    energy = np.linalg.norm(field.embedding)
            elif hasattr(field, 'semantic_state'):
                energy = sum(field.semantic_state.values()) if field.semantic_state else 0.0
            else:
                energy = float(field) if isinstance(field, (int, float)) else 1.0
            
            energies.append(energy)
        
        # Normalize to probability distribution
        total_energy = sum(energies)
        if total_energy == 0:
            return 0.0
        
        probabilities = np.array(energies) / total_energy
        
        # Boltzmann entropy S = -k_B * Î£ p_i * ln(p_i)
        entropy = -np.sum(probabilities * np.log(probabilities + 1e-12))
        
        return float(entropy)
    
    def calculate_entropy(self, field_data: Union[np.ndarray, List[float], torch.Tensor]) -> float:
        """
        Calculate thermodynamic entropy of field data
        
        Args:
            field_data: Field values as array, list, or tensor
            
        Returns:
            float: Entropy value
        """
        # Convert to numpy array
        if isinstance(field_data, torch.Tensor):
            data = field_data.cpu().numpy() if field_data.is_cuda else field_data.numpy()
        elif isinstance(field_data, list):
            data = np.array(field_data)
        else:
            data = field_data
            
        # Flatten if multidimensional
        data = data.flatten()
        
        # Calculate Shannon entropy
        # First normalize to probability distribution
        data_positive = np.abs(data) + 1e-10  # Ensure positive
        data_normalized = data_positive / np.sum(data_positive)
        
        # Calculate entropy
        entropy_value = -np.sum(data_normalized * np.log(data_normalized + 1e-10))
        
        return float(entropy_value)
    
    def _calculate_thermodynamic_entropy(self, fields: List[Any]) -> float:
        """
        Calculate thermodynamic entropy for a collection of fields
        """
        if not fields:
            return 0.0
            
        entropies = []
        for field in fields:
            if hasattr(field, 'embedding'):
                # Handle embedding fields
                if hasattr(field.embedding, 'cpu'):
                    entropy = self.calculate_entropy(field.embedding)
                else:
                    entropy = self.calculate_entropy(field.embedding)
            elif hasattr(field, 'semantic_state'):
                # Handle geoid fields
                values = list(field.semantic_state.values()) if field.semantic_state else [0.0]
                entropy = self.calculate_entropy(values)
            elif isinstance(field, (list, np.ndarray, torch.Tensor)):
                entropy = self.calculate_entropy(field)
            else:
                # Single value
                entropy = 0.0
                
            entropies.append(entropy)
            
        return np.mean(entropies) if entropies else 0.0
    
    def _calculate_phase_transition_proximity(self, fields: List[Any]) -> float:
        """
        Calculate proximity to complexity phase transition
        
        Phase transitions occur when dÂ²F/dTÂ² â‰ˆ 0 (critical point)
        """
        if len(fields) < 3:
            return 0.0
        
        # Calculate free energy as function of temperature
        temperatures = []
        free_energies = []
        
        # Sample different temperature regimes
        for i in range(3):
            # Create temperature variations
            temp_factor = 0.5 + i * 0.5  # 0.5, 1.0, 1.5
            
            # Calculate free energy at this temperature
            epistemic_temp = self.calculate_epistemic_temperature(fields)
            temp = epistemic_temp.get_validated_temperature() * temp_factor
            entropy = self._calculate_thermodynamic_entropy(fields)
            energy = self._calculate_total_energy(fields)
            
            free_energy = energy - temp * entropy
            
            temperatures.append(temp)
            free_energies.append(free_energy)
        
        # Calculate second derivative dÂ²F/dTÂ²
        if len(temperatures) < 3:
            return 0.0
        
        # Using finite differences
        d2F_dT2 = (free_energies[2] - 2*free_energies[1] + free_energies[0]) / \
                  ((temperatures[1] - temperatures[0])**2 + 1e-10)
        
        # Proximity to critical point (small second derivative)
        proximity = 1.0 / (1.0 + abs(d2F_dT2))
        
        return min(proximity, 1.0)
    
    def get_physics_compliance_report(self) -> Dict[str, Any]:
        """Generate comprehensive physics compliance report"""
        total_cycles = len(self.carnot_cycles)
        violations = len(self.physics_violations)
        
        if total_cycles == 0:
            return {
                'total_cycles': 0,
                'physics_violations': 0,
                'compliance_rate': 1.0,
                'average_efficiency': 0.0,
                'average_confidence': 0.0
            }
        
        compliant_cycles = [c for c in self.carnot_cycles if c.physics_compliant]
        compliance_rate = len(compliant_cycles) / total_cycles
        
        average_efficiency = np.mean([c.actual_efficiency for c in self.carnot_cycles])
        average_confidence = np.mean([c.epistemic_confidence for c in self.carnot_cycles])
        
        return {
            'total_cycles': total_cycles,
            'physics_violations': violations,
            'compliance_rate': compliance_rate,
            'average_efficiency': average_efficiency,
            'average_confidence': average_confidence,
            'violation_details': self.physics_violations,
            'mode': self.mode.value
        }


class EpistemicTemperatureProcessor:
    """Processor for epistemic temperature calculations"""
    
    def __init__(self):
        self.settings = get_api_settings()
        logger.debug(f"   Environment: {self.settings.environment}")
        self.temperature_models = {
            'statistical_mechanics': self._statistical_mechanics_temperature,
            'information_theoretic': self._information_theoretic_temperature,
            'fluctuation_dissipation': self._fluctuation_dissipation_temperature
        }
    
    def _statistical_mechanics_temperature(self, energies: List[float]) -> float:
        """Statistical mechanics temperature calculation"""
        if not energies:
            return 0.001
        
        mean_energy = np.mean(energies)
        return (2.0 * mean_energy) / (3.0 * 1.0)  # Equipartition theorem
    
    def _information_theoretic_temperature(self, energies: List[float]) -> float:
        """Information-theoretic temperature"""
        if len(energies) < 2:
            return 0.001
        
        entropy = -np.sum(np.array(energies) * np.log(np.array(energies) + 1e-12))
        mean_energy = np.mean(energies)
        
        return mean_energy / (entropy + 0.001)
    
    def _fluctuation_dissipation_temperature(self, energies: List[float]) -> float:
        """Fluctuation-dissipation theorem temperature"""
        if len(energies) < 2:
            return 0.001
        
        variance = np.var(energies)
        mean_energy = np.mean(energies)
        
        return variance / (mean_energy + 0.001)


class ConsciousnessThermodynamicDetector:
    """Detector for consciousness emergence through thermodynamics"""
    
    def __init__(self):
        self.settings = get_api_settings()
        logger.debug(f"   Environment: {self.settings.environment}")
        self.consciousness_indicators = [
            'temperature_coherence',
            'information_integration',
            'phase_transition_proximity',
            'entropy_organization',
            'free_energy_minimization'
        ]


class AdaptivePhysicsValidator:
    """Adaptive validator for physics compliance"""
    
    def __init__(self):
        self.settings = get_api_settings()
        logger.debug(f"   Environment: {self.settings.environment}")
        self.violation_threshold = 0.01
        self.correction_strategies = {
            'carnot_violation': self._correct_carnot_violation,
            'energy_conservation': self._correct_energy_conservation,
            'entropy_decrease': self._correct_entropy_decrease
        }
    
    def _correct_carnot_violation(self, measured_eff: float, theoretical_eff: float) -> float:
        """Correct Carnot efficiency violations"""
        return min(measured_eff, theoretical_eff * 0.99)
    
    def _correct_energy_conservation(self, energy_in: float, energy_out: float) -> float:
        """Correct energy conservation violations"""
        return min(energy_out, energy_in)
    
    def _correct_entropy_decrease(self, entropy_before: float, entropy_after: float) -> float:
        """Correct entropy decrease violations"""
        return max(entropy_after, entropy_before)


# Factory function for easy instantiation
def create_revolutionary_engine(mode: str = "hybrid") -> FoundationalThermodynamicEngine:
    """Create revolutionary thermodynamic engine with specified mode"""
    mode_enum = ThermodynamicMode(mode.lower())
    return FoundationalThermodynamicEngine(mode_enum) 